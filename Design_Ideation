Design of Optimized_Network_On_a_Chip:

Latency:
Given the problem of limited speed due to increased latency in the case of the architecture at hand, we aim to find ways of better context switching and arbitration rates which help us achieve better performance in terms of speedup. We can adjust the weights of thr round robin arbitrator making use if genetic algorithms. We can formulate the equation for speedup using different factors such as message retrieval timings in case of throttled and non-throttled state inputs, static timing analysis parameters such as setup time and hold time and other important parameters that could be responsible for introducing delay into the system. The logic for prefetchers can also be similarly arrived at using particle swarm optimization algorithm, to simulate an impartial and fair prefetching mechanism. These two algorithms will make sure that the vast variety of traffic present in the SoC can be dealt with in an efficient manner because of the manner in which population and swarm updates are made. The formulation of fitness function would play a crucial role in the success of this approach. 

Power:
The problem of power efficiency can be dealt in a similar manner as speedup, the throttling rates can be reduced by employing Reinforcement Learning Algorithms to achieve the desired throttling rate which is less than 5%. The rewards and penalties to the system can be well adjusted to the Deep Q Learning approach, given the nature of the throttling problem since the level of throttling can be categorised into ranges without significant loss of generality. For this problem, we can use the DQN reinforcement learning algorithm and dicretize our action space into three categories: no throttling, low throttling and high throttling.  

Buffer size:
For solving the memory and area mismanagement problem, we can use the Action-Critic Reinfrocement learning criteria because it can act as a policy as well as value based learning system, giving us flexible grounds to test our system on. The area and buffer occupancy problem can be thought of as a reinforcement learning problem, where we reward the system numerically when it reaches close to its maximum possible space efficiency, while linearly penalizing it is in the still relatively high occupancy area and imposing heavy penalty as the level of area efficiency drops down towards the minimum threshold. 

Throughput:
The throughput of a system can be improved if the bandwidth of the system is as high as possible. This becomes a maximization problem for us in terms of data transfer and the rate of data transfer in an noc depends upon the efficiency of routing algorithms. I would like to propose dimension order routing, an adaptive selection method along with a torus toplogy to improve the same.


